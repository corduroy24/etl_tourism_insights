{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The project aims to leverage data engineering techniques to analyze and forecast tourism patterns and trends. It ingests and processes 2 data sets related to immigration, and weather detials. These features are further utilized to assist with tourism planning and enable accruate forecating of tourist arrivals. The value of such an itiative lies with the contribituon of economic development that tourism provides. Interest is in the number of immigrants for a country, on a month by month basis. Note this projects takes into account 2 stakeholders of the data. One that will be situated with analytical tasks, the other with forecasting.\n",
    "\n",
    "The project follows the following steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, count, isnan, when\n",
    "from pyspark.sql import SparkSession\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "<!-- Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc> -->\n",
    "\n",
    "The purpose of the project is tourism planning and forecasting. Where relevant datasets can be used to develop predictive models. By analyzing historical immigration data, temperature patterns, city demographics, and airport details, these models can be leveraged to identify areas of opportunity and optimize tourism strategies. The clients considered in the scope of this project are government agencies, travel companies, and marketing iniatives.\n",
    "\n",
    "[comment]: <> (This is a comment, it will not be included)\n",
    "\n",
    "[//]: <> (This is also a comment.)\n",
    "\n",
    "#### Describe and Gather Data \n",
    "<!-- Describe the data sets you're using. Where did it come from? What type of information is included? -->\n",
    "\n",
    "I94 Immigration Data: \n",
    "- Source: https://www.trade.gov/national-travel-and-tourism-office\n",
    "- Features: comphrehensive demographic and travel information\n",
    "\n",
    "World Temperature Data: \n",
    "- Source: https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data\n",
    "- Features: time series of temperature segmented by country and city\n",
    "\n",
    "<!-- U.S. City Demographic Data: \n",
    "- Source: https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "- Features: the demographics of all US cities and census-designated places (population >= 65,000)\n",
    "\n",
    "Airport Code Table:\n",
    "- Source: https://datahub.io/core/airport-codes#data\n",
    "- Features: airport codes and corresponding cities -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "# airport = pd.read_csv('airport-codes_csv.csv')\n",
    "# demo = pd.read_csv('us-cities-demographics.csv')\n",
    "\n",
    "\n",
    "immi = pd.read_csv('immigration_data_sample.csv')\n",
    "# i94 = pd.read_sas('I94_SAS_Labels_Descriptions.SAS')\n",
    "\n",
    "fname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temp = pd.read_csv(fname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsd = {}\n",
    "# # for dataset in datasets:\n",
    "#     dsd[dataset] = pd.read_sas(dataset+\".sas7bdat\", encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port',\n",
       "       'arrdate', 'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa',\n",
       "       'count', 'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd',\n",
       "       'entdepu', 'matflag', 'biryear', 'dtaddto', 'gender', 'insnum',\n",
       "       'airline', 'admnum', 'fltno', 'visatype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Ã…rhus   \n",
       "1  1743-12-01                 NaN                            NaN  Ã…rhus   \n",
       "2  1744-01-01                 NaN                            NaN  Ã…rhus   \n",
       "3  1744-02-01                 NaN                            NaN  Ã…rhus   \n",
       "4  1744-03-01                 NaN                            NaN  Ã…rhus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>'MEXICO Air Sea, and Not Reported (I-94, no l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>'AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>'ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>'ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>'ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code                                            Country\n",
       "0   582   'MEXICO Air Sea, and Not Reported (I-94, no l...\n",
       "1   236                                       'AFGHANISTAN\n",
       "2   101                                           'ALBANIA\n",
       "3   316                                           'ALGERIA\n",
       "4   102                                           'ANDORRA"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to your data file\n",
    "data_file_path = \"country_name.txt\"\n",
    "\n",
    "# Read the data file\n",
    "with open(data_file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Create a dictionary to store the mappings\n",
    "country_mapping = {}\n",
    "\n",
    "# Process each line and extract the code and name\n",
    "for line in lines:\n",
    "    code, name = line.strip().split(\" = \")\n",
    "    code = int(code)\n",
    "    name = name.strip(\"'\")\n",
    "    country_mapping[code] = name\n",
    "# print(country_mapping)\n",
    "country_name = pd.DataFrame(list(country_mapping.items()), columns=['Code', 'Country'])\n",
    "country_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "immi = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "\n",
    "# folder_path = '../../data/18-83510-I94-Data-2016/'\n",
    "\n",
    "# Get a list files\n",
    "# file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.sas7bdat')]\n",
    "# immi = spark.read.format(\"com.github.saurfang.sas.spark\").load(file_paths)\n",
    "immi.show(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "# temp = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|             6.068|           1.7369999999999999|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01 00:00:00|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01 00:00:00|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01 00:00:00|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01 00:00:00|              null|                         null|Ã…rhus|Denmark|  57.05N|   10.33E|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# temp.show(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|Code|             Country|\n",
      "+----+--------------------+\n",
      "| 582| 'MEXICO Air Sea,...|\n",
      "| 236|        'AFGHANISTAN|\n",
      "| 101|            'ALBANIA|\n",
      "| 316|            'ALGERIA|\n",
      "| 102|            'ANDORRA|\n",
      "+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# country_name = spark.createDataFrame(country_name)\n",
    "# country_name.show(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|  occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto|gender| insnum|airline|admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "|    0|    0|     0|     0|     0|      0|      0|    239| 152592| 142457|   802|      0|    0|       1| 1881250|3088187|    238| 138429|3095921| 138429|    802|    477|414269|2982605|  83627|     0|19549|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+------+-----+--------+\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'immigration_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a7f4ec000d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmissing_values_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mduplicate_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimmigration_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimmigration_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mduplicate_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'immigration_df' is not defined"
     ]
    }
   ],
   "source": [
    "using the sample data/pandas\n",
    "immi.isna().sum()/immi.shape[0]*100\n",
    "immi.dtypes\n",
    "len(immi)-len(immi.drop_duplicates())\n",
    "\n",
    "# using spark\n",
    "# missing_values_count = immi.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in immi.columns])\n",
    "# missing_values_count.show()\n",
    "\n",
    "# duplicate_count = immi.groupBy(immi.columns).count().where(col(\"count\") > 1)\n",
    "# duplicate_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      0.0\n",
       "cicid           0.0\n",
       "i94yr           0.0\n",
       "i94mon          0.0\n",
       "i94cit          0.0\n",
       "i94res          0.0\n",
       "i94port         0.0\n",
       "arrdate         0.0\n",
       "i94mode         0.0\n",
       "i94addr         5.9\n",
       "depdate         4.9\n",
       "i94bir          0.0\n",
       "i94visa         0.0\n",
       "count           0.0\n",
       "dtadfile        0.0\n",
       "visapost       61.8\n",
       "occup          99.6\n",
       "entdepa         0.0\n",
       "entdepd         4.6\n",
       "entdepu       100.0\n",
       "matflag         4.6\n",
       "biryear         0.0\n",
       "dtaddto         0.0\n",
       "gender         14.1\n",
       "insnum         96.5\n",
       "airline         3.3\n",
       "admnum          0.0\n",
       "fltno           0.8\n",
       "visatype        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "cicid         float64\n",
       "i94yr         float64\n",
       "i94mon        float64\n",
       "i94cit        float64\n",
       "i94res        float64\n",
       "i94port        object\n",
       "arrdate       float64\n",
       "i94mode       float64\n",
       "i94addr        object\n",
       "depdate       float64\n",
       "i94bir        float64\n",
       "i94visa       float64\n",
       "count         float64\n",
       "dtadfile        int64\n",
       "visapost       object\n",
       "occup          object\n",
       "entdepa        object\n",
       "entdepd        object\n",
       "entdepu       float64\n",
       "matflag        object\n",
       "biryear       float64\n",
       "dtaddto        object\n",
       "gender         object\n",
       "insnum        float64\n",
       "airline        object\n",
       "admnum        float64\n",
       "fltno          object\n",
       "visatype       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi.shape[0]\n",
    "immi.isna().sum()/immi.shape[0]*100\n",
    "immi.dtypes\n",
    "len(immi)-len(immi.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8599212"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dt                               0.000000\n",
       "AverageTemperature               4.234458\n",
       "AverageTemperatureUncertainty    4.234458\n",
       "City                             0.000000\n",
       "Country                          0.000000\n",
       "Latitude                         0.000000\n",
       "Longitude                        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dt                                object\n",
       "AverageTemperature               float64\n",
       "AverageTemperatureUncertainty    float64\n",
       "City                              object\n",
       "Country                           object\n",
       "Latitude                          object\n",
       "Longitude                         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas\n",
    "temp.shape[0]\n",
    "temp.isna().sum()/temp.shape[0]*100\n",
    "temp.dtypes\n",
    "len(temp)-len(temp.drop_duplicates())\n",
    "\n",
    "# using spark\n",
    "\n",
    "# missing_values_count = temp.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in temp.columns])\n",
    "# missing_values_count.show()\n",
    "\n",
    "# duplicate_count = temp.groupBy(temp.columns).count().where(col(\"count\") > 1)\n",
    "# duplicate_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- For each of the data sets we took a look at the percentage of missing values for each column.\n",
    "\n",
    "Since we do not yet know which columns will be used for joining the data. We will proceed by droping rows that have more than 30% missing values. Duplicates can be removed. -->\n",
    "\n",
    "\n",
    "The 2 columns of most interest for joining the data set have no missing values in the immigration data. (ie,m i94cit, i94mon). Therefore, we dont have much cause for concern and all rows can be kept. We have that some of the country codes are of a float type. For analytical and forecasting purposes this would be problematic. There are no duplicates found in the data set\n",
    "\n",
    "\n",
    "Note that, the temperature data is already aggregated by month, and there exists some missing values. Temperature ius presumed to be a significant feature in this data set. So having 4% missing values is not ideal. Since it is only 4%, we can either remove those rows (losing insight) or fill in the missing data. To proceed, we will drop the rows. Although, if we did want to fill by mean, we would have to consider a partition for each country ordered by data to ensure quality temperatures. \n",
    "\n",
    "\n",
    "Also, the temperature data set only contains data up until 2013, wheras the forecasting data goes up until 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "# immi2 = immi.select(\"i94yr\", \"i94mon\", \"i94cit\", \"i94res\", \"i94port\", \"i94mode\", \"i94addr\", \"i94visa\") \\\n",
    "\n",
    "immi2 = immi[[\"i94yr\", \"i94mon\", \"i94cit\", \"i94res\", \"i94port\", \"i94mode\", \"i94addr\", \"i94visa\"]]\n",
    "\n",
    "temp2 = temp.dropna()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "(this includes Data dictionary )\n",
    "<!-- Map out the conceptual data model and explain why you chose that model -->\n",
    "\n",
    "Immigration: Fact table; captures the primary facts\n",
    "- i94yr: Year of immigration\n",
    "- i94mon: Month of immigration\n",
    "- i94cit: Origin country code\n",
    "- i94res: Residence country code\n",
    "- i94port: Port of entry code\n",
    "- i94mode: Mode of transportation code\n",
    "- i94addr: US state code of destination\n",
    "- i94visa: Visa category code\n",
    "- count: Count of immigrants\n",
    "\n",
    "Temperature: Dimension table; additional details\n",
    "- Country: Country name\n",
    "- dt: Date\n",
    "- AverageTemperature: Average temperature\n",
    "\n",
    "Country: Dimension table; additional details\n",
    "- CountryCode: Country code\n",
    "- CountryName: Country name\n",
    "\n",
    "A star schema representation (relational data model) utilizes SQL queries that provide a foundation for performing analytical tasks, explorations (descriptive) and predictive analytics for different use-cases. Further more, it simple, flexible and scalable, considers relationships between data, promots consistency and data integrity, and is easy to work with. \n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "<!-- List the steps necessary to pipeline the data into the chosen data model -->\n",
    "1. Retrieve data (data extraction)\n",
    "2. Data Preprocessing \n",
    "3. Aggregate and transform data \n",
    "\n",
    "\n",
    "For ongoing analysis we would considering the following additional steps\n",
    "\n",
    "4. Create tables in data base \n",
    "5. Load data to database \n",
    "6. Data validation\n",
    "7. Data storage \n",
    "8. Storage optimization and maintenance\n",
    "9. Periodic updates \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1743</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>5.788</td>\n",
       "      <td>3.624</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.283</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>14.051</td>\n",
       "      <td>1.347</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "      <td>1744</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Ã…rhus   \n",
       "5 1744-04-01               5.788                          3.624  Ã…rhus   \n",
       "6 1744-05-01              10.644                          1.283  Ã…rhus   \n",
       "7 1744-06-01              14.051                          1.347  Ã…rhus   \n",
       "8 1744-07-01              16.082                          1.396  Ã…rhus   \n",
       "\n",
       "   Country Latitude Longitude  year  month  \n",
       "0  Denmark   57.05N    10.33E  1743     11  \n",
       "5  Denmark   57.05N    10.33E  1744      4  \n",
       "6  Denmark   57.05N    10.33E  1744      5  \n",
       "7  Denmark   57.05N    10.33E  1744      6  \n",
       "8  Denmark   57.05N    10.33E  1744      7  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2['dt'] = pd.to_datetime(temp2['dt'])\n",
    "# temp2.dtypes\n",
    "\n",
    "temp2['year'] = temp2['dt'].dt.year\n",
    "temp2['month'] = temp2['dt'].dt.month\n",
    "\n",
    "temp2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2013"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2.year.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>i94visa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94yr  i94mon  i94cit  i94res i94port  i94mode i94addr  i94visa\n",
       "0   2016       4   209.0   209.0     HHW      1.0      HI      2.0\n",
       "1   2016       4   582.0   582.0     MCA      1.0      TX      2.0\n",
       "2   2016       4   148.0   112.0     OGG      1.0      FL      2.0\n",
       "3   2016       4   297.0   297.0     LOS      1.0      CA      2.0\n",
       "4   2016       4   111.0   111.0     CHM      3.0      NY      2.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immi2['i94yr'] = immi2['i94yr'].astype(int)\n",
    "immi2['i94mon'] = immi2['i94mon'].astype(int)\n",
    "immi2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('capstone_project.db')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7f0a1cbf8c00>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.execute('''\n",
    "    CREATE TABLE immigration_data (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        country TEXT,\n",
    "        date DATE,\n",
    "        visitor_type TEXT,\n",
    "        visitor_count INTEGER,\n",
    "        visa_type TEXT,\n",
    "        duration_of_stay INTEGER,\n",
    "        port_of_entry TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "conn.execute('''\n",
    "    CREATE TABLE country_names (\n",
    "        country_code TEXT PRIMARY KEY,\n",
    "        country_name TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Create the temperature_data table\n",
    "conn.execute('''\n",
    "    CREATE TABLE temperature_data (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        country_code TEXT,\n",
    "        date DATE,\n",
    "        average_temperature FLOAT,\n",
    "        temperature_uncertainty FLOAT\n",
    "    )\n",
    "''')\n",
    "\n",
    "\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>i94visa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   i94yr  i94mon  i94cit  i94res i94port  i94mode i94addr  i94visa\n",
       "0      0  2016.0     4.0   209.0   209.0     HHW      1.0      HI      2.0\n",
       "1      1  2016.0     4.0   582.0   582.0     MCA      1.0      TX      2.0\n",
       "2      2  2016.0     4.0   148.0   112.0     OGG      1.0      FL      2.0\n",
       "3      3  2016.0     4.0   297.0   297.0     LOS      1.0      CA      2.0\n",
       "4      4  2016.0     4.0   111.0   111.0     CHM      3.0      NY      2.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Upload the DataFrame to the database\n",
    "immi3 = immi2.reset_index()\n",
    "immi3.head()\n",
    "immi3.to_sql('immigration_data', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dt</th>\n",
       "      <th>Country</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>5.788</td>\n",
       "      <td>3.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>14.051</td>\n",
       "      <td>1.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         dt  Country  AverageTemperature  \\\n",
       "0      0 1743-11-01  Denmark               6.068   \n",
       "1      5 1744-04-01  Denmark               5.788   \n",
       "2      6 1744-05-01  Denmark              10.644   \n",
       "3      7 1744-06-01  Denmark              14.051   \n",
       "4      8 1744-07-01  Denmark              16.082   \n",
       "\n",
       "   AverageTemperatureUncertainty  \n",
       "0                          1.737  \n",
       "1                          3.624  \n",
       "2                          1.283  \n",
       "3                          1.347  \n",
       "4                          1.396  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp3 = temp2.reset_index()\n",
    "temp3 = temp3[['index', 'dt', 'Country', 'AverageTemperature', 'AverageTemperatureUncertainty']]\n",
    "temp3.head()\n",
    "\n",
    "temp3.to_sql('temperature_data', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_name.to_sql('country_names', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "immi_df = pd.read_sql_query('SELECT * FROM immigration_data', conn)\n",
    "print(immi_df.index.is_unique)\n",
    "\n",
    "\n",
    "temp_df = pd.read_sql_query('SELECT * FROM temperature_data', conn)\n",
    "print(immi_df.index.is_unique)\n",
    "\n",
    "\n",
    "country_df = pd.read_sql_query('SELECT * FROM country_names', conn)\n",
    "print(country_df.Code.is_unique)\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "<!-- Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file. -->\n",
    "\n",
    "\n",
    "Country Names:\n",
    "\n",
    "- country_code (Text): The unique code representing a country. It is sourced from the original country code dataset.\n",
    "- country_name (Text): The name of the country corresponding to the country code. It is sourced from the original country name dataset.\n",
    "\n",
    "Temperature Data Table:\n",
    "\n",
    "- country_code (Text): The unique code representing a country. It is sourced from the original temperature dataset.\n",
    "- year (Integer): The year for which the temperature data is recorded. It is sourced from the original temperature dataset.\n",
    "- month (Integer): The month for which the temperature data is recorded. It is extracted from the original date field in the temperature dataset.\n",
    "- temperature (Float): The temperature value recorded for the specific country, year, and month. It is sourced from the original temperature dataset.\n",
    "\n",
    "Immigration Data Table:\n",
    "\n",
    "- country_code (Text): The unique code representing a country. It is sourced from the original immigration dataset.\n",
    "- year (Integer): The year for which the immigration data is recorded. It is sourced from the original immigration dataset.\n",
    "- month (Integer): The month for which the immigration data is recorded. It is sourced from the original immigration dataset.\n",
    "<!-- - count (Integer): The count of immigration events for the specific country, year, and month. It is sourced from the original immigration dataset. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "<!-- * Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people. -->\n",
    "\n",
    "**Choice of tools**\n",
    "Python: Python is a versatile and widely-used programming language with rich libraries and frameworks for data processing, analysis, and manipulation. It provides a large ecosystem of tools that make it well-suited for tasks like data cleaning, transformation, and analysis.\n",
    "\n",
    "Pandas: \n",
    "- data manipulation library in Python that provides high-performance\n",
    "- easy-to-use data structures and data analysis tools\n",
    "- efficient data handling capabilities; such as data filtering, aggregation, merging, and transformation\n",
    "\n",
    "SQL\n",
    "- relational database management system that is easy to set up and use.\n",
    "- suitable for local development and testing purposes where there is no need for complex database infrastructure. \n",
    "- good compatibility with Python and supports widely known SQL queries.\n",
    "\n",
    "**Frequency of data update**\n",
    "- Country data: is static and does not require updating\n",
    "- Immigration data: Update monthly or quarterly, depending the availability. Since the analysis would like to have it has granular as possible\n",
    "- Temperature: update daily to get the latest trends for quality decision-making\n",
    "\n",
    "**Other Considerations**\n",
    " * The data was increased by 100x.\n",
    "    - Switch to distributed data processing framework like Apache Spark. Since Spark can handle large-scale data and perform distributed processing to achieve scalability and performance.\n",
    "    \n",
    "* The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    - Automate the data pipeline to ensure it runs at a specific time every day, preferably during off-peak hours to minimize disruption.\n",
    "    - Utilize scheduling tools like cron jobs or job schedulers (e.g., Apache Airflow) to manage and trigger the data pipeline at the desired time.\n",
    " \n",
    "* The database needed to be accessed by 100+ people.\n",
    "    - Optimize query performance and scaling up the infrasture to handle cocurrent connections and query loads\n",
    "    - Use Redis to optimize performance and reduce database load\n",
    "\n",
    "\n",
    " \n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
